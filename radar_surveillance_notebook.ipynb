## Summary and Analysis

This notebook has successfully implemented a comprehensive radar surveillance classification system with the following key features:

### Data Generation
- ✅ 100,000 radar records with temporal continuity
- ✅ 25 realistic ship tracks with consistent movement patterns
- ✅ 50 sea clutter sources with appropriate characteristics
- ✅ All required features: range, azimuth, elevation, doppler, bearing, RCS, SNR

### Machine Learning Implementation
- ✅ Random Forest classifier for traditional feature-based classification
- ✅ LSTM-RNN model for time-series pattern recognition
- ✅ Proper train/validation/test splits
- ✅ Comprehensive evaluation metrics

### Visualization
- ✅ PPI (Plan Position Indicator) radar display
- ✅ Color-coded true labels and predictions
- ✅ Misclassification highlighting
- ✅ Range rings and proper radar formatting

### Interactive Features
- ✅ Real-time prediction interface
- ✅ Dual model comparison
- ✅ Confidence scoring
- ✅ User-friendly parameter adjustment

### Key Insights
1. **Feature Importance**: SNR, RCS, and Doppler are typically the most discriminative features
2. **Model Performance**: Both models should achieve high accuracy (>95%) on this synthetic data
3. **Temporal Patterns**: LSTM can capture movement continuity that Random Forest cannot
4. **Real-world Applicability**: The system demonstrates practical radar classification techniques

### Usage in Google Colab
This notebook is designed to run seamlessly in Google Colab with:
- Automatic package installation
- Interactive widgets for parameter adjustment
- Clear documentation and modular code structure
- Comprehensive visualizations

The system provides a solid foundation for maritime radar surveillance applications and can be extended with additional features such as multi-target tracking, advanced clutter filtering, and real-time data integration.# Example predictions with typical scenarios
print("Example Classifications:")
print("\n1. Typical Ship Target:")
predict_classification(25000, 45, 2, 15, 225, 18, 25)

print("\n2. Sea Clutter:")
predict_classification(8000, 120, 0.5, 2, 300, 5, 8)

print("\n3. Fast Moving Target:")
predict_classification(35000, 270, 3, 28, 90, 22, 30)## Quick Prediction Function

For users who prefer manual input:def predict_classification(range_val, azimuth_val, elevation_val, doppler_val, 
                         bearing_val, rcs_val, snr_val):
    """
    Predict classification using both models for user input.
    """
    # Prepare input data
    user_input = np.array([[range_val, azimuth_val, elevation_val, doppler_val, 
                           bearing_val, rcs_val, snr_val]])
    
    # Random Forest prediction
    rf_pred = rf_model.predict(user_input)[0]
    rf_prob = rf_model.predict_proba(user_input)[0]
    
    # For LSTM, we need a sequence - we'll replicate the input
    user_input_scaled = scaler.transform(user_input)
    lstm_input = np.tile(user_input_scaled, (seq_length, 1)).reshape(1, seq_length, -1)
    lstm_prob = lstm_model.predict(lstm_input, verbose=0)[0][0]
    lstm_pred = 1 if lstm_prob > 0.5 else 0
    
    # Display results
    print("\n" + "="*50)
    print("RADAR CLASSIFICATION RESULTS")
    print("="*50)
    print(f"Input Parameters:")
    print(f"  Range: {range_val:,.0f} m")
    print(f"  Azimuth: {azimuth_val:.1f}°")
    print(f"  Elevation: {elevation_val:.1f}°")
    print(f"  Doppler: {doppler_val:.1f} m/s")
    print(f"  Bearing: {bearing_val:.1f}°")
    print(f"  RCS: {rcs_val:.1f} dBsm")
    print(f"  SNR: {snr_val:.1f} dB")
    print("\nClassification Results:")
    print(f"  Random Forest: {'TRACK' if rf_pred == 1 else 'CLUTTER'} (confidence: {max(rf_prob):.2%})")
    print(f"  LSTM Neural Network: {'TRACK' if lstm_pred == 1 else 'CLUTTER'} (confidence: {lstm_prob if lstm_pred == 1 else 1-lstm_prob:.2%})")
    
    if rf_pred == lstm_pred:
        print(f"\n✓ Both models agree: This appears to be a {'TRACK' if rf_pred == 1 else 'CLUTTER'}")
    else:
        print(f"\n⚠ Models disagree - recommend further analysis")
    print("="*50)

# Create interactive widgets
range_widget = widgets.FloatSlider(value=15000, min=500, max=50000, step=500, 
                                  description='Range (m):')
azimuth_widget = widgets.FloatSlider(value=180, min=0, max=360, step=1, 
                                    description='Azimuth (°):')
elevation_widget = widgets.FloatSlider(value=2, min=-10, max=15, step=0.1, 
                                      description='Elevation (°):')
doppler_widget = widgets.FloatSlider(value=10, min=-50, max=50, step=0.5, 
                                    description='Doppler (m/s):')
bearing_widget = widgets.FloatSlider(value=0, min=0, max=360, step=1, 
                                    description='Bearing (°):')
rcs_widget = widgets.FloatSlider(value=15, min=-20, max=30, step=0.5, 
                                description='RCS (dBsm):')
snr_widget = widgets.FloatSlider(value=20, min=-10, max=40, step=0.5, 
                                description='SNR (dB):')

# Create interactive interface
print("Interactive Radar Classification System")
print("Adjust the parameters below to classify radar contacts:")

interact(predict_classification,
         range_val=range_widget,
         azimuth_val=azimuth_widget,
         elevation_val=elevation_widget,
         doppler_val=doppler_widget,
         bearing_val=bearing_widget,
         rcs_val=rcs_widget,
         snr_val=snr_widget);## 6. Interactive Prediction

Create an interactive interface for users to input radar parameters and get predictions from both models:def create_ppi_display(radar_data, rf_predictions=None, lstm_predictions=None, sample_size=5000):
    """
    Create a PPI (Plan Position Indicator) display of radar data.
    """
    # Sample data for visualization (to avoid overcrowding)
    sample_indices = np.random.choice(len(radar_data), min(sample_size, len(radar_data)), replace=False)
    sample_data = radar_data.iloc[sample_indices].copy()
    
    # Convert polar to cartesian coordinates
    x = sample_data['range'] * np.cos(np.radians(sample_data['azimuth']))
    y = sample_data['range'] * np.sin(np.radians(sample_data['azimuth']))
    
    # Create figure with subplots
    fig, axes = plt.subplots(1, 3, figsize=(24, 8))
    
    # 1. True Labels
    for label, color in [('track', 'green'), ('clutter', 'red')]:
        mask = sample_data['label'] == label
        axes[0].scatter(x[mask], y[mask], c=color, label=f'True {label.capitalize()}', 
                       s=20, alpha=0.6)
    
    axes[0].set_title('True Labels', fontsize=14)
    axes[0].set_xlabel('East (m)')
    axes[0].set_ylabel('North (m)')
    axes[0].legend()
    axes[0].grid(True, alpha=0.3)
    axes[0].set_aspect('equal')
    
    # Add range rings
    for ring_range in [10000, 20000, 30000, 40000, 50000]:
        circle = plt.Circle((0, 0), ring_range, fill=False, color='gray', alpha=0.3, linestyle='--')
        axes[0].add_patch(circle)
        axes[0].text(ring_range/np.sqrt(2), ring_range/np.sqrt(2), f'{ring_range/1000:.0f}km', 
                    fontsize=8, alpha=0.7)
    
    # 2. Random Forest Predictions
    if rf_predictions is not None:
        rf_sample_pred = rf_predictions[sample_indices]
        true_labels = (sample_data['label'] == 'track').astype(int)
        
        # Color code: Green=correct track, Red=correct clutter, Orange=misclassification
        colors = []
        for true_label, pred_label in zip(true_labels, rf_sample_pred):
            if true_label == 1 and pred_label == 1:  # True track, predicted track
                colors.append('green')
            elif true_label == 0 and pred_label == 0:  # True clutter, predicted clutter
                colors.append('red')
            else:  # Misclassification
                colors.append('orange')
        
        axes[1].scatter(x, y, c=colors, s=20, alpha=0.6)
        
        # Create custom legend
        from matplotlib.patches import Patch
        legend_elements = [
            Patch(facecolor='green', label='Correct Track'),
            Patch(facecolor='red', label='Correct Clutter'),
            Patch(facecolor='orange', label='Misclassified')
        ]
        axes[1].legend(handles=legend_elements)
    
    axes[1].set_title('Random Forest Predictions', fontsize=14)
    axes[1].set_xlabel('East (m)')
    axes[1].set_ylabel('North (m)')
    axes[1].grid(True, alpha=0.3)
    axes[1].set_aspect('equal')
    
    # Add range rings
    for ring_range in [10000, 20000, 30000, 40000, 50000]:
        circle = plt.Circle((0, 0), ring_range, fill=False, color='gray', alpha=0.3, linestyle='--')
        axes[1].add_patch(circle)
    
    # 3. SNR visualization
    scatter = axes[2].scatter(x, y, c=sample_data['SNR'], s=20, alpha=0.6, cmap='viridis')
    plt.colorbar(scatter, ax=axes[2], label='SNR (dB)')
    axes[2].set_title('SNR Distribution', fontsize=14)
    
    axes[2].set_xlabel('East (m)')
    axes[2].set_ylabel('North (m)')
    axes[2].grid(True, alpha=0.3)
    axes[2].set_aspect('equal')
    
    # Add range rings
    for ring_range in [10000, 20000, 30000, 40000, 50000]:
        circle = plt.Circle((0, 0), ring_range, fill=False, color='gray', alpha=0.3, linestyle='--')
        axes[2].add_patch(circle)
    
    plt.tight_layout()
    plt.show()

# Create PPI display
print("Creating PPI Display...")
create_ppi_display(radar_data, rf_results['y_pred'])## 5. PPI Visualization

Create a Plan Position Indicator (PPI) display showing the radar scene with color-coded classifications:def evaluate_model(model, X_test, y_test, model_name, is_lstm=False):
    """
    Evaluate a model and return comprehensive metrics.
    """
    if is_lstm:
        y_pred_proba = model.predict(X_test, verbose=0).flatten()
        y_pred = (y_pred_proba > 0.5).astype(int)
    else:
        y_pred = model.predict(X_test)
        y_pred_proba = model.predict_proba(X_test)[:, 1]
    
    # Calculate metrics
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    roc_auc = roc_auc_score(y_test, y_pred_proba)
    
    print(f"\n{model_name} Performance:")
    print(f"Accuracy: {accuracy:.4f}")
    print(f"Precision: {precision:.4f}")
    print(f"Recall: {recall:.4f}")
    print(f"F1-Score: {f1:.4f}")
    print(f"ROC-AUC: {roc_auc:.4f}")
    
    # Confusion Matrix
    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                xticklabels=['Clutter', 'Track'], 
                yticklabels=['Clutter', 'Track'])
    plt.title(f'{model_name} Confusion Matrix')
    plt.ylabel('True Label')
    plt.xlabel('Predicted Label')
    plt.show()
    
    return {
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1': f1,
        'roc_auc': roc_auc,
        'y_pred': y_pred,
        'y_pred_proba': y_pred_proba
    }

# Evaluate Random Forest
rf_results = evaluate_model(rf_model, X_test, y_test, "Random Forest")

# Evaluate LSTM
lstm_results = evaluate_model(lstm_model, X_test_lstm, y_test_lstm, "LSTM", is_lstm=True)

# Compare models
comparison_df = pd.DataFrame({
    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC'],
    'Random Forest': [rf_results['accuracy'], rf_results['precision'], 
                     rf_results['recall'], rf_results['f1'], rf_results['roc_auc']],
    'LSTM': [lstm_results['accuracy'], lstm_results['precision'], 
            lstm_results['recall'], lstm_results['f1'], lstm_results['roc_auc']]
})

print("\nModel Comparison:")
print(comparison_df.round(4))

# Visualize comparison
plt.figure(figsize=(12, 6))
x = np.arange(len(comparison_df['Metric']))
width = 0.35

plt.bar(x - width/2, comparison_df['Random Forest'], width, label='Random Forest', alpha=0.8)
plt.bar(x + width/2, comparison_df['LSTM'], width, label='LSTM', alpha=0.8)

plt.xlabel('Metrics')
plt.ylabel('Score')
plt.title('Model Performance Comparison')
plt.xticks(x, comparison_df['Metric'])
plt.legend()
plt.ylim(0, 1)
plt.grid(axis='y', alpha=0.3)

for i, (rf_val, lstm_val) in enumerate(zip(comparison_df['Random Forest'], comparison_df['LSTM'])):
    plt.text(i - width/2, rf_val + 0.01, f'{rf_val:.3f}', ha='center', va='bottom')
    plt.text(i + width/2, lstm_val + 0.01, f'{lstm_val:.3f}', ha='center', va='bottom')

plt.tight_layout()
plt.show()## 4. Model Evaluation

Let's evaluate both models using comprehensive metrics:# Build LSTM model
def build_lstm_model(input_shape):
    model = Sequential([
        LSTM(64, return_sequences=True, input_shape=input_shape),
        Dropout(0.2),
        LSTM(32, return_sequences=False),
        Dropout(0.2),
        Dense(16, activation='relu'),
        Dropout(0.2),
        Dense(1, activation='sigmoid')
    ])
    
    model.compile(
        optimizer=Adam(learning_rate=0.001),
        loss='binary_crossentropy',
        metrics=['accuracy']
    )
    
    return model

# Train LSTM model
print("Training LSTM model...")
lstm_model = build_lstm_model((seq_length, len(feature_columns)))

# Train the model
history = lstm_model.fit(
    X_train_lstm, y_train_lstm,
    validation_data=(X_val_lstm, y_val_lstm),
    epochs=20,
    batch_size=32,
    verbose=1
)

# Plot training history
plt.figure(figsize=(12, 4))

plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

plt.tight_layout()
plt.show()

print("LSTM training completed!")def create_sequences(X, y, seq_length=10):
    """
    Create sequences for LSTM training.
    Groups consecutive records by object ID to maintain temporal continuity.
    """
    # Get the corresponding radar data for indexing
    radar_subset = radar_data.iloc[:len(X)].copy()
    
    sequences_X = []
    sequences_y = []
    
    # Group by object ID to maintain temporal sequences
    for obj_id in radar_subset['id'].unique():
        obj_indices = radar_subset[radar_subset['id'] == obj_id].index
        obj_data = X[obj_indices]
        obj_labels = y[obj_indices]
        
        # Create sequences from this object's data
        for i in range(len(obj_data) - seq_length + 1):
            sequences_X.append(obj_data[i:i+seq_length])
            sequences_y.append(obj_labels[i+seq_length-1])  # Predict the last label in sequence
    
    return np.array(sequences_X), np.array(sequences_y)

# Create sequences for LSTM
print("Creating sequences for LSTM...")
seq_length = 10  # Use 10 time steps

# We need to recreate the train/val/test split to maintain object continuity
# First, get unique object IDs
unique_ids = radar_data['id'].unique()
train_ids, temp_ids = train_test_split(unique_ids, test_size=0.4, random_state=42)
val_ids, test_ids = train_test_split(temp_ids, test_size=0.5, random_state=42)

# Create datasets based on object IDs
train_mask = radar_data['id'].isin(train_ids)
val_mask = radar_data['id'].isin(val_ids)
test_mask = radar_data['id'].isin(test_ids)

X_train_seq = radar_data[train_mask][feature_columns].values
y_train_seq = (radar_data[train_mask]['label'] == 'track').astype(int).values

X_val_seq = radar_data[val_mask][feature_columns].values
y_val_seq = (radar_data[val_mask]['label'] == 'track').astype(int).values

X_test_seq = radar_data[test_mask][feature_columns].values
y_test_seq = (radar_data[test_mask]['label'] == 'track').astype(int).values

# Scale the sequence data
seq_scaler = StandardScaler()
X_train_seq_scaled = seq_scaler.fit_transform(X_train_seq)
X_val_seq_scaled = seq_scaler.transform(X_val_seq)
X_test_seq_scaled = seq_scaler.transform(X_test_seq)

# Create sequences
X_train_lstm, y_train_lstm = create_sequences(X_train_seq_scaled, y_train_seq, seq_length)
X_val_lstm, y_val_lstm = create_sequences(X_val_seq_scaled, y_val_seq, seq_length)
X_test_lstm, y_test_lstm = create_sequences(X_test_seq_scaled, y_test_seq, seq_length)

print(f"LSTM Training sequences: {X_train_lstm.shape}")
print(f"LSTM Validation sequences: {X_val_lstm.shape}")
print(f"LSTM Test sequences: {X_test_lstm.shape}")### LSTM-RNN Model for Time Series# Train Random Forest classifier
print("Training Random Forest classifier...")
rf_model = RandomForestClassifier(
    n_estimators=100,
    max_depth=20,
    min_samples_split=5,
    min_samples_leaf=2,
    random_state=42,
    n_jobs=-1
)

rf_model.fit(X_train, y_train)

# Feature importance
feature_importance = pd.DataFrame({
    'feature': feature_columns,
    'importance': rf_model.feature_importances_
}).sort_values('importance', ascending=False)

plt.figure(figsize=(10, 6))
sns.barplot(data=feature_importance, x='importance', y='feature')
plt.title('Random Forest Feature Importance')
plt.xlabel('Importance Score')
plt.show()

print("Random Forest training completed!")### Random Forest Classifier# Prepare features and labels
feature_columns = ['range', 'azimuth', 'elevation', 'doppler', 'bearing', 'RCS', 'SNR']
X = radar_data[feature_columns].values
y = (radar_data['label'] == 'track').astype(int)  # 1 for track, 0 for clutter

# Split data for traditional ML (Random Forest)
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42, stratify=y)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)

print(f"Training set: {X_train.shape[0]} samples")
print(f"Validation set: {X_val.shape[0]} samples")
print(f"Test set: {X_test.shape[0]} samples")

# Scale features for neural network
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_val_scaled = scaler.transform(X_val)
X_test_scaled = scaler.transform(X_test)## 3. Machine Learning Models

We'll implement two classification models:
1. Random Forest (traditional ML approach)
2. LSTM-based RNN (deep learning for time series)

### Data Preparation# Data exploration
print("Dataset Info:")
print(radar_data.info())
print("\nDataset Statistics:")
print(radar_data.describe())
print("\nLabel Distribution:")
print(radar_data['label'].value_counts())

# Visualize feature distributions
fig, axes = plt.subplots(2, 4, figsize=(20, 10))
features = ['range', 'azimuth', 'elevation', 'doppler', 'bearing', 'RCS', 'SNR']

for i, feature in enumerate(features):
    row = i // 4
    col = i % 4
    
    for label in ['track', 'clutter']:
        data_subset = radar_data[radar_data['label'] == label][feature]
        axes[row, col].hist(data_subset, alpha=0.7, label=label, bins=50)
    
    axes[row, col].set_title(f'{feature} Distribution')
    axes[row, col].set_xlabel(feature)
    axes[row, col].set_ylabel('Frequency')
    axes[row, col].legend()

# Remove empty subplot
fig.delaxes(axes[1, 3])
plt.tight_layout()
plt.show()

# Create correlation matrix
plt.figure(figsize=(10, 8))
correlation_matrix = radar_data[features].corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)
plt.title('Feature Correlation Matrix')
plt.show()## 2. Data Preprocessing

Let's examine the data distribution and prepare it for machine learning:def generate_radar_data(n_records=100000, n_tracks=25, n_clutter=50):
    """
    Generate realistic radar surveillance data with tracks and clutter.
    
    Parameters:
    - n_records: Total number of radar records to generate
    - n_tracks: Number of actual target tracks
    - n_clutter: Number of sea clutter sources
    
    Returns:
    - DataFrame with radar data
    """
    
    data = []
    object_id = 0
    
    # Calculate records per object
    total_objects = n_tracks + n_clutter
    records_per_object = n_records // total_objects
    
    # Generate tracks (actual targets)
    for track_id in range(n_tracks):
        # Initial position and movement parameters for each track
        initial_range = np.random.uniform(1000, 50000)  # 1-50 km
        initial_azimuth = np.random.uniform(0, 360)     # 0-360 degrees
        initial_elevation = np.random.uniform(-5, 10)   # -5 to 10 degrees
        
        # Movement parameters
        speed = np.random.uniform(5, 30)  # 5-30 m/s (typical ship speeds)
        course = np.random.uniform(0, 360)  # Course in degrees
        
        # Track characteristics
        base_rcs = np.random.uniform(5, 25)  # Base RCS for ships (dBsm)
        base_snr = np.random.uniform(15, 35)  # Good SNR for actual targets
        
        for i in range(records_per_object):
            # Time progression (1 second intervals)
            timestamp = i
            
            # Position evolution over time
            # Simple linear movement model
            dx = speed * np.cos(np.radians(course)) * i
            dy = speed * np.sin(np.radians(course)) * i
            
            # Convert to polar coordinates
            x = initial_range * np.cos(np.radians(initial_azimuth)) + dx
            y = initial_range * np.sin(np.radians(initial_azimuth)) + dy
            
            current_range = np.sqrt(x**2 + y**2)
            current_azimuth = np.degrees(np.arctan2(y, x)) % 360
            
            # Add some noise but maintain continuity
            range_noise = np.random.normal(0, current_range * 0.001)  # 0.1% noise
            azimuth_noise = np.random.normal(0, 0.1)  # 0.1 degree noise
            elevation_noise = np.random.normal(0, 0.05)  # Small elevation noise
            
            # Doppler calculation (radial velocity)
            bearing_to_radar = np.radians(current_azimuth + 180)  # Bearing from target to radar
            radial_velocity = speed * np.cos(np.radians(course) - bearing_to_radar)
            doppler = radial_velocity + np.random.normal(0, 0.5)  # Add noise
            
            # RCS and SNR with some variation
            rcs = base_rcs + np.random.normal(0, 2)  # ±2 dB variation
            snr = base_snr + np.random.normal(0, 3)  # ±3 dB variation
            
            data.append({
                'id': f'T{track_id:03d}',
                'range': current_range + range_noise,
                'azimuth': (current_azimuth + azimuth_noise) % 360,
                'elevation': initial_elevation + elevation_noise,
                'doppler': doppler,
                'bearing': (current_azimuth + 180) % 360,  # Bearing from radar to target
                'RCS': rcs,
                'SNR': snr,
                'timestamp': timestamp,
                'label': 'track'
            })
    
    # Generate clutter sources
    for clutter_id in range(n_clutter):
        # Clutter sources are typically stationary or slow-moving
        base_range = np.random.uniform(500, 30000)  # Closer to shore typically
        base_azimuth = np.random.uniform(0, 360)
        base_elevation = np.random.uniform(-2, 5)  # Usually lower elevation
        
        # Clutter characteristics
        base_rcs = np.random.uniform(-10, 15)  # Lower and more variable RCS
        base_snr = np.random.uniform(0, 20)    # Lower SNR
        
        for i in range(records_per_object):
            timestamp = i
            
            # Clutter has more random movement (waves, etc.)
            range_variation = np.random.normal(0, base_range * 0.01)  # 1% variation
            azimuth_variation = np.random.normal(0, 1)  # More azimuth variation
            elevation_variation = np.random.normal(0, 0.2)  # More elevation variation
            
            # Clutter typically has low or random doppler
            doppler = np.random.normal(0, 2)  # Random small doppler
            
            # More variable RCS and SNR for clutter
            rcs = base_rcs + np.random.normal(0, 5)  # ±5 dB variation
            snr = base_snr + np.random.normal(0, 5)  # ±5 dB variation
            
            data.append({
                'id': f'C{clutter_id:03d}',
                'range': base_range + range_variation,
                'azimuth': (base_azimuth + azimuth_variation) % 360,
                'elevation': base_elevation + elevation_variation,
                'doppler': doppler,
                'bearing': (base_azimuth + 180 + np.random.normal(0, 2)) % 360,
                'RCS': rcs,
                'SNR': snr,
                'timestamp': timestamp,
                'label': 'clutter'
            })
    
    # Create DataFrame and sort by timestamp for temporal continuity
    df = pd.DataFrame(data)
    df = df.sort_values(['timestamp', 'id']).reset_index(drop=True)
    
    return df

# Generate the radar data
print("Generating radar data...")
radar_data = generate_radar_data(n_records=100000, n_tracks=25, n_clutter=50)
print(f"Generated {len(radar_data)} radar records")
print(f"Tracks: {len(radar_data[radar_data['label'] == 'track'])} records")
print(f"Clutter: {len(radar_data[radar_data['label'] == 'clutter'])} records")

# Display first few records
radar_data.head(10)## 1. Data Generation

We'll generate realistic radar data with the following characteristics:
- 25 actual targets (tracks) with consistent movement patterns
- 50 sea clutter sources with random characteristics
- 100,000 total records with temporal continuity
- Features: id, range, azimuth, elevation, doppler, bearing, RCS, SNR, timestamp, label# Install required packages
!pip install numpy pandas matplotlib seaborn scikit-learn tensorflow plotly ipywidgets

# Import libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.optimizers import Adam
import plotly.graph_objects as go
import plotly.express as px
from ipywidgets import interact, widgets
import warnings
warnings.filterwarnings('ignore')

# Set random seeds for reproducibility
np.random.seed(42)
tf.random.set_seed(42)

print("All packages imported successfully!")